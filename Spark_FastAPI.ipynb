{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi0kNwYn1K68",
        "outputId": "423d2d8f-35fb-42cc-9287-825ee8013d42"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-05-07T11:37:19+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n",
            "WARNING:pyngrok.process.ngrok:t=2023-05-07T11:37:19+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: https://fa87-35-229-138-112.ngrok-free.app\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [259]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     42.1.70.196:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     42.1.70.196:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     42.1.70.196:0 - \"POST /predict HTTP/1.1\" 400 Bad Request\n",
            "RandomForest Classifier - Accuracy: 0.925531914893617\n",
            "INFO:     42.1.70.196:0 - \"POST /train HTTP/1.1\" 200 OK\n",
            "INFO:     42.1.70.196:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "RandomForest Classifier - Accuracy: 0.925531914893617\n",
            "INFO:     42.1.70.196:0 - \"POST /train HTTP/1.1\" 200 OK\n",
            "INFO:     42.1.70.196:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "Received form data: {'baseline_value': 1.0, 'accelerations': 1.0, 'fetal_movement': 1.0, 'uterine_contractions': 1.0, 'light_decelerations': 1.0, 'severe_decelerations': 1.0, 'prolongued_decelerations': 1.0, 'abnormal_short_term_variability': 1.0, 'mean_value_of_short_term_variability': 1.0, 'percentage_of_time_with_abnormal_long_term_variability': 1.0, 'mean_value_of_long_term_variability': 1.0, 'histogram_width': 1.0, 'histogram_min': 1.0, 'histogram_max': 1.0, 'histogram_number_of_peaks': 1.0, 'histogram_number_of_zeroes': 1.0, 'histogram_mode': 1.0, 'histogram_mean': 1.0, 'histogram_median': 1.0, 'histogram_variance': 1.0, 'histogram_tendency': 1.0}\n",
            "Input dataframe:    baseline_value  accelerations  fetal_movement  uterine_contractions  \\\n",
            "0             1.0            1.0             1.0                   1.0   \n",
            "\n",
            "   light_decelerations  severe_decelerations  prolongued_decelerations  \\\n",
            "0                  1.0                   1.0                       1.0   \n",
            "\n",
            "   abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n",
            "0                              1.0                                   1.0   \n",
            "\n",
            "   percentage_of_time_with_abnormal_long_term_variability  ...  \\\n",
            "0                                                1.0       ...   \n",
            "\n",
            "   histogram_width  histogram_min  histogram_max  histogram_number_of_peaks  \\\n",
            "0              1.0            1.0            1.0                        1.0   \n",
            "\n",
            "   histogram_number_of_zeroes  histogram_mode  histogram_mean  \\\n",
            "0                         1.0             1.0             1.0   \n",
            "\n",
            "   histogram_median  histogram_variance  histogram_tendency  \n",
            "0               1.0                 1.0                 1.0  \n",
            "\n",
            "[1 rows x 21 columns]\n",
            "INFO:     42.1.70.196:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     42.1.70.196:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "RandomForest Classifier - Accuracy: 0.925531914893617\n",
            "INFO:     42.1.70.196:0 - \"POST /train HTTP/1.1\" 200 OK\n",
            "INFO:     42.1.70.196:0 - \"GET / HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [259]\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "from fastapi.responses import HTMLResponse\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from pydantic import BaseModel\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "\n",
        "from fastapi import FastAPI, HTTPException, Request, Form, Depends\n",
        "from fastapi.responses import JSONResponse\n",
        "from fastapi.encoders import jsonable_encoder\n",
        "\n",
        "# Import your PySpark ML model and preprocessing functions here\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml.feature import Imputer\n",
        "from pyspark.ml.tuning import TrainValidationSplit\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# enable CORS\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        "    expose_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "\n",
        "# Add the following line to mount static files\n",
        "# app.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\n",
        "\n",
        "templates = Jinja2Templates(directory=\"templates\")\n",
        "\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def serve_homepage(request: Request):\n",
        "    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n",
        "\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Fetal Health Prediction\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.python.worker.memory\", \"2g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "data = spark.read.csv(\"/content/fetal_health.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Handle missing values (if any)\n",
        "imputer = Imputer(strategy='mean', inputCols=data.columns, outputCols=data.columns)\n",
        "data = imputer.fit(data).transform(data)\n",
        "\n",
        "# Assemble features into a single vector\n",
        "feature_columns = data.columns[:-1]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "# feature scaling\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "\n",
        "# Create pipeline for preprocessing\n",
        "pipeline = Pipeline(stages=[assembler, scaler])\n",
        "\n",
        "# Fit the pipeline and transform the data\n",
        "preprocessing_pipeline_model = pipeline.fit(data)\n",
        "preprocessed_data = preprocessing_pipeline_model.transform(data) #Just got this fixed up\n",
        "\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_data, test_data = preprocessed_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Create a RandomForest model\n",
        "rf = RandomForestClassifier(labelCol=\"fetal_health\", featuresCol=\"scaled_features\", numTrees=100, seed=42)\n",
        "\n",
        "# Define input data schema\n",
        "class InputData(BaseModel):\n",
        "    baseline_value: float\n",
        "    accelerations: float\n",
        "    fetal_movement: float\n",
        "    uterine_contractions: float\n",
        "    light_decelerations: float\n",
        "    severe_decelerations: float\n",
        "    prolongued_decelerations: float\n",
        "    abnormal_short_term_variability: float\n",
        "    mean_value_of_short_term_variability: float\n",
        "    percentage_of_time_with_abnormal_long_term_variability: float\n",
        "    mean_value_of_long_term_variability: float\n",
        "    histogram_width: float\n",
        "    histogram_min: float\n",
        "    histogram_max: float\n",
        "    histogram_number_of_peaks: float\n",
        "    histogram_number_of_zeroes: float\n",
        "    histogram_mode: float\n",
        "    histogram_mean: float\n",
        "    histogram_median: float\n",
        "    histogram_variance: float\n",
        "    histogram_tendency: float\n",
        "\n",
        "trained_model = None\n",
        "accuracy_result = None\n",
        "\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def serve_homepage(request: Request):\n",
        "    return templates.TemplateResponse(\"index.html\", {\"request\": request, \"accuracy\": accuracy_result})\n",
        "\n",
        "@app.post(\"/train\")\n",
        "async def train_model(request: Request):\n",
        "    global trained_model, accuracy_result\n",
        "    # Load the dataset, preprocess, and train the model\n",
        "    from pyspark.ml.classification import RandomForestClassifier\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "    # Create a RandomForest model\n",
        "    rf = RandomForestClassifier(labelCol=\"fetal_health\", featuresCol=\"scaled_features\", numTrees=100, seed=42)\n",
        "\n",
        "    # Update the pipelines without assembler and scaler stages\n",
        "    rf_pipeline = Pipeline(stages=[rf])\n",
        "\n",
        "    # Train the models\n",
        "    trained_model = rf_pipeline.fit(train_data)\n",
        "\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol=\"fetal_health\", predictionCol=\"prediction\")\n",
        "    rf_accuracy = evaluator.evaluate(trained_model.transform(test_data), {evaluator.metricName: \"accuracy\"})\n",
        "\n",
        "    accuracy_result = rf_accuracy\n",
        "\n",
        "    print(\"RandomForest Classifier - Accuracy:\", rf_accuracy)\n",
        "\n",
        "    trained_model.write().overwrite().save(\"fetal_health_prediction_model\")\n",
        "\n",
        "    # return {\"status\": \"Model trained successfully\", \"accuracy\": rf_accuracy}\n",
        "    return templates.TemplateResponse(\"result.html\", {\"request\": request, \"status\": \"Model trained successfully: ✅\", \"accuracy\": rf_accuracy})\n",
        "\n",
        "@app.post(\"/predict\", response_class=JSONResponse)\n",
        "async def predict(request: Request,\n",
        "    baseline_value : float = Form(...),\n",
        "    accelerations: float = Form(...),\n",
        "    fetal_movement: float = Form(...),\n",
        "    uterine_contractions: float = Form(...),\n",
        "    light_decelerations: float = Form(...),\n",
        "    severe_decelerations: float = Form(...),\n",
        "    prolongued_decelerations: float = Form(...),\n",
        "    abnormal_short_term_variability: float = Form(...),\n",
        "    mean_value_of_short_term_variability: float = Form(...),\n",
        "    percentage_of_time_with_abnormal_long_term_variability: float = Form(...),\n",
        "    mean_value_of_long_term_variability: float = Form(...),\n",
        "    histogram_width: float = Form(...),\n",
        "    histogram_min: float = Form(...),\n",
        "    histogram_max: float = Form(...),\n",
        "    histogram_number_of_peaks: float = Form(...),\n",
        "    histogram_number_of_zeroes: float = Form(...),\n",
        "    histogram_mode: float = Form(...),\n",
        "    histogram_mean: float = Form(...),\n",
        "    histogram_median: float = Form(...),\n",
        "    histogram_variance: float = Form(...),\n",
        "    histogram_tendency: float = Form(...)\n",
        "):\n",
        "    global trained_model\n",
        "    if not trained_model:\n",
        "        raise HTTPException(status_code=400, detail=\"Model not trained. Please train the model first.\")\n",
        "    \n",
        "    input_data = {\n",
        "        \"baseline_value\": baseline_value,\n",
        "        \"accelerations\": accelerations,\n",
        "        \"fetal_movement\": fetal_movement,\n",
        "        \"uterine_contractions\": uterine_contractions,\n",
        "        \"light_decelerations\": light_decelerations,\n",
        "        \"severe_decelerations\": severe_decelerations,\n",
        "        \"prolongued_decelerations\": prolongued_decelerations,\n",
        "        \"abnormal_short_term_variability\": abnormal_short_term_variability,\n",
        "        \"mean_value_of_short_term_variability\": mean_value_of_short_term_variability,\n",
        "        \"percentage_of_time_with_abnormal_long_term_variability\": percentage_of_time_with_abnormal_long_term_variability,\n",
        "        \"mean_value_of_long_term_variability\": mean_value_of_long_term_variability,\n",
        "        \"histogram_width\": histogram_width,\n",
        "        \"histogram_min\": histogram_min,\n",
        "        \"histogram_max\": histogram_max,\n",
        "        \"histogram_number_of_peaks\": histogram_number_of_peaks,\n",
        "        \"histogram_number_of_zeroes\": histogram_number_of_zeroes,\n",
        "        \"histogram_mode\": histogram_mode,\n",
        "        \"histogram_mean\": histogram_mean,\n",
        "        \"histogram_median\": histogram_median,\n",
        "        \"histogram_variance\": histogram_variance,\n",
        "        \"histogram_tendency\": histogram_tendency\n",
        "    }\n",
        "\n",
        "    print(\"Received form data:\", {\n",
        "        \"baseline_value\": baseline_value,\n",
        "        \"accelerations\": accelerations,\n",
        "        \"fetal_movement\": fetal_movement,\n",
        "        \"uterine_contractions\": uterine_contractions,\n",
        "        \"light_decelerations\": light_decelerations,\n",
        "        \"severe_decelerations\": severe_decelerations,\n",
        "        \"prolongued_decelerations\": prolongued_decelerations,\n",
        "        \"abnormal_short_term_variability\": abnormal_short_term_variability,\n",
        "        \"mean_value_of_short_term_variability\": mean_value_of_short_term_variability,\n",
        "        \"percentage_of_time_with_abnormal_long_term_variability\": percentage_of_time_with_abnormal_long_term_variability,\n",
        "        \"mean_value_of_long_term_variability\": mean_value_of_long_term_variability,\n",
        "        \"histogram_width\": histogram_width,\n",
        "        \"histogram_min\": histogram_min,\n",
        "        \"histogram_max\": histogram_max,\n",
        "        \"histogram_number_of_peaks\": histogram_number_of_peaks,\n",
        "        \"histogram_number_of_zeroes\": histogram_number_of_zeroes,\n",
        "        \"histogram_mode\": histogram_mode,\n",
        "        \"histogram_mean\": histogram_mean,\n",
        "        \"histogram_median\": histogram_median,\n",
        "        \"histogram_variance\": histogram_variance,\n",
        "        \"histogram_tendency\": histogram_tendency\n",
        "    })\n",
        "\n",
        "\n",
        "    # Preprocess the input data and make predictions\n",
        "    input_df = pd.DataFrame([input_data])\n",
        "    input_spark_df = spark.createDataFrame(input_df)\n",
        "\n",
        "    preprocessed_input = preprocessing_pipeline_model.transform(input_spark_df)\n",
        "\n",
        "    # Make predictions using the trained model\n",
        "    predictions = trained_model.transform(preprocessed_input)\n",
        "\n",
        "    # Collect the predictions\n",
        "    prediction_result = predictions.collect()\n",
        "\n",
        "    # Extract the predicted labels\n",
        "    predicted_labels = [result[\"prediction\"] for result in prediction_result]\n",
        "\n",
        "    print(\"Input dataframe:\", input_df)\n",
        "    \n",
        "    # return {\"predictions\": predicted_labels[0]}\n",
        "    if predicted_labels[0]==1:\n",
        "      predicted_labels = \"Normal ✅\"\n",
        "    elif predicted_labels[0]==2:\n",
        "      predicted_labels = \"Suspicious 🤷‍♂️\"\n",
        "    else:\n",
        "      predicted_labels = \"Pathological 💀\"\n",
        "    return templates.TemplateResponse(\"predict.html\", {\"request\": request, \"prediction_result\": predicted_labels})\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     uvicorn.run(\"main:app\", host=\"127.0.0.1\", port=8000, reload=True)\n",
        "\n",
        "# ngrok_tunnel = ngrok.connect(8000)\n",
        "# print('Public URL:', ngrok_tunnel.public_url)\n",
        "# nest_asyncio.apply()\n",
        "# uvicorn.run(app, port=8000)\n",
        "\n",
        "\n",
        "# ngrok_tunnel = ngrok.connect(8000)\n",
        "# print('New public URL:', ngrok_tunnel.public_url)\n",
        "\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
